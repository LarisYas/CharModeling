{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn, optim, Tensor \n",
    "from torch.nn import functional as F \n",
    "from torchmetrics import Accuracy \n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "import numpy as np \n",
    "import os \n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/heroes_of_our_times.txt', 'r') as file:\n",
    "    text = file.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set(text)\n",
    "chars.symmetric_difference_update(set(int2char.tolist()))\n",
    "chars - set(int2char.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/', 'V', '“', '„'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars - set(int2char.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k', '/', 'C', 'Й', 'x', '“', 'a', 'F', '’', 'v', 'y', '€', 'j', 'b', 'V', 'M', 'q', 'f', '„', 'Ь', 'g', 'z', 'd', 'Ы', 'N'}\n"
     ]
    }
   ],
   "source": [
    "chars.symmetric_difference_update(set(int2char.tolist()))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list()\n",
    "int2char = np.array(list(set(text)))\n",
    "char2int = {char : idx for idx, char in enumerate(int2char.tolist())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoded = [char2int[char] for char in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModelingDatasets(Dataset):\n",
    "    def __init__(self, chunks):\n",
    "        self.chunks = chunks \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.chunks) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks[idx]\n",
    "        return chunk[:-1], chunk[1:].to(torch.int64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModelingModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                vocab_size, emb_dim, \n",
    "                rnn_hidden_dim, fc_hidden_dim, \n",
    "                rnn_drop, fc_drop,\n",
    "                num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=emb_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=rnn_hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=rnn_drop\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_dim, fc_hidden_dim),\n",
    "            nn.BatchNorm1d(fc_hidden_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(fc_drop),\n",
    "            nn.Linear(fc_hidden_dim, vocab_size)\n",
    "        )\n",
    "        \n",
    "        self.num_layers = num_layers \n",
    "        self.hidden_size = rnn_hidden_dim\n",
    "    \n",
    "    def forward(self, inputs: Tensor, hidden: Tensor, cell: Tensor):\n",
    "        inputs = self.embedding(inputs.unsqueeze(1))\n",
    "        outputs, (hidden, cell) = self.lstm(inputs, (hidden, cell))\n",
    "        outputs = self.classifier(outputs.squeeze(1))\n",
    "        return outputs, (hidden, cell)\n",
    "    \n",
    "    def init_hidden_cell(self, batch_size):\n",
    "        device = next(self.parameters()).device\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden.to(device), cell.to(device)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 200\n",
    "chunk_length = seq_length + 1\n",
    "\n",
    "chunks = [ torch.tensor(\n",
    "    text_encoded[idx : idx+chunk_length]) for idx in range(len(text_encoded) - chunk_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CharModelingDatasets(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_dl = DataLoader(\n",
    "    train_data,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "#    num_workers=os.cpu_count(),\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(\n",
    "    model,\n",
    "    train_dl,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    metric,\n",
    "    device,\n",
    "    epochs):\n",
    "    \n",
    "    model.train() \n",
    "    best_loss = float('inf')\n",
    "    best_metric = None \n",
    "    best_epoch = None \n",
    "    train_loop = tqdm(range(epochs), desc='[Train]', leave=False)\n",
    "    \n",
    "    for epoch in train_loop:\n",
    "        optimizer.zero_grad()\n",
    "        x_batch, y_target = next(iter(train_dl))\n",
    "        x_batch, y_target = x_batch.to(device), y_target.to(device)\n",
    "        hidden, cell = model.init_hidden_cell(batch_size)\n",
    "        loss = 0\n",
    "        cur_metric = 0\n",
    "        for idx in range(seq_length):\n",
    "            y_pred, (hidden, cell) = model(x_batch[:, idx], hidden, cell)\n",
    "            loss += loss_fn(y_pred, y_target[:, idx])\n",
    "            cur_metric += metric(y_pred, y_target[:, idx])\n",
    "        \n",
    "        loss /= seq_length\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        cur_metric /= seq_length\n",
    "        \n",
    "        loss, cur_metric = loss.item(), cur_metric.item() \n",
    "        train_loop.set_description(desc=f'[Train] Epoch {epoch + 1}: loss={loss:.3f}, metric={cur_metric:.3f}')\n",
    "        \n",
    "        if loss < best_loss:\n",
    "            best_loss = loss \n",
    "            best_metric = cur_metric\n",
    "            best_epoch = epoch + 1\n",
    "            \n",
    "            \n",
    "    with open(\"../results/hero_results.txt\", \"w+\") as file:\n",
    "        file.write(f'Обучение модели на тексте \"Герой нашего времени\"\\n' + \n",
    "                    f'Лучшая эпоха: {best_epoch}\\n' + \n",
    "                    f'Лучший лосс: {best_loss:.3f}\\n' + \n",
    "                    f'Лучшая метрика: {best_metric:.3f}')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(int2char)\n",
    "emb_dim = 256\n",
    "rnn_hidden_dim = 256\n",
    "fc_hidden_dim = 256\n",
    "rnn_drop = 0.2\n",
    "fc_drop = 0.4\n",
    "num_layers = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu ')\n",
    "\n",
    "model = CharModelingModel(\n",
    "    vocab_size,\n",
    "    emb_dim,\n",
    "    rnn_hidden_dim,\n",
    "    fc_hidden_dim,\n",
    "    rnn_drop,\n",
    "    fc_drop,\n",
    "    num_layers\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-3\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric = Accuracy(task='multiclass', num_classes=vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    }
   ],
   "source": [
    "trainer(\n",
    "    model, \n",
    "    train_dl,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    metric,\n",
    "    device,\n",
    "    epochs=3500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharModelingModel(\n",
       "  (embedding): Embedding(127, 256)\n",
       "  (lstm): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=127, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(start_string, len_generate=500, temperature=1.0):\n",
    "    str_encoded = torch.tensor([char2int[char] for char in start_string]).view(1, -1).to(device)\n",
    "    \n",
    "    \n",
    "    hidden, cell = model.init_hidden_cell(1)\n",
    "    for idx in range(len(start_string) - 1):\n",
    "        _, (hidden, cell) = model(str_encoded[:, idx], hidden, cell)\n",
    "    \n",
    "    last_char = str_encoded[:, -1]\n",
    "    generated_text = start_string\n",
    "     \n",
    "    for _ in range(len_generate):\n",
    "        logits, (hidden, cell) = model(last_char, hidden, cell)\n",
    "        logits = temperature * logits \n",
    "        sampler = Categorical(logits=logits)\n",
    "        last_char = sampler.sample()\n",
    "        generated_text += f'{int2char[last_char]}'\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharModelingModel(\n",
       "  (embedding): Embedding(127, 256)\n",
       "  (lstm): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=127, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Приветный Пугачеву. Тело было заставлять ее в моих положении. Я все стоял на деревушку, и все предвещало скорое и благополучное окончание.Вскоре князь Голицын, под крепостию Татищевой, разбил Пугачева, рассеял его толпы, освободил Оренбург и, казалось, нанес бунту последний и решительный удар. Зурин был в то время отряжен противу шайки мятежных башкирцев, которые рассеялись прежде, нежели мы их увидали. Весна осадила нас в татарской деревушке. Речки разлились, и дороги стали непроходимы. Мы утешались '"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Привет\", temperature=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'epoch': 10500,\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict(),\n",
    "    'loss' : 0.503,\n",
    "    'metric' : 0.843\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, '../checkpoints/checkpoint_hero/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'loss', 'metric'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('../checkpoints/checkpoint_hero/checkpoint.pth').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/captain_daughter_utf8.txt', 'r') as file:\n",
    "    text = file.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('/', '').replace('V', '').replace('“', '').replace('„', '') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/captain_daughter_utf8.txt', 'w+') as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = set(text)\n",
    "chars.symmetric_difference_update(set(int2char.tolist()))\n",
    "chars - set(int2char.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Капитанская дочкаАлександр Сер'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение на \"Капитанская дочка\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'epoch' : 5000,\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict(),\n",
    "    'best_loss' : 0.367,\n",
    "    'best_metric' : 0.881\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, '../checkpoints/checkpoint_capitan/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    }
   ],
   "source": [
    "trainer(\n",
    "    model, \n",
    "    train_dl,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    metric,\n",
    "    device,\n",
    "    epochs=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharModelingModel(\n",
       "  (embedding): Embedding(127, 256)\n",
       "  (lstm): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=127, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Свобода… Она выпустила мою одежду, и я слышал, как она не убьешь, что наши приятеля, своивал ее болезнью, я заглебил и обугаться; и положив его следом. Разбудил я.–\\xa0Не может быть, не забуду! Потому что я люб'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('Свобода', temperature=3, len_generate=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
